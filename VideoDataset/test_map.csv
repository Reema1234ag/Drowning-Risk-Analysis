{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "DrowningRiskAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reema1234ag/Drowning-Risk-Analysis/blob/master/VideoDataset/test_map.csv\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "910p03-nfBQ9",
        "outputId": "e3468c87-e7df-4d18-e2b2-16d865980625"
      },
      "source": [
        "!git clone https://github.com/Reema1234ag/Drowning-Risk-Analysis.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Drowning-Risk-Analysis'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 3397 (delta 29), reused 20 (delta 8), pack-reused 3321\u001b[K\n",
            "Receiving objects: 100% (3397/3397), 862.82 MiB | 34.09 MiB/s, done.\n",
            "Resolving deltas: 100% (1303/1303), done.\n",
            "Checking out files: 100% (3083/3083), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOHBsAdKm0jG",
        "outputId": "14ddbb5a-7240-447e-8db0-5edc00a95ce8"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import csv\n",
        "import sys\n",
        "import numpy as np\n",
        "import imageio\n",
        "\n",
        "import ssl\n",
        "\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "try:\n",
        "    from urllib.request import urlretrieve\n",
        "except ImportError:\n",
        "    from urllib import urlretrieve\n",
        "\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "def download_and_extract(src):\n",
        "    print ('Downloading ' + src)\n",
        "    zip_file, h = urlretrieve(src, './delete.me')\n",
        "    print ('Done downloading, start extracting.')\n",
        "    try:\n",
        "        with ZipFile(zip_file, 'r') as zfile:\n",
        "            zfile.extractall('.')\n",
        "            print ('Done extracting.')\n",
        "    finally:\n",
        "        os.remove(zip_file)\n",
        "\n",
        "def load_groups(input_folder):\n",
        "    '''\n",
        "    Load the list of sub-folders into a python list with their\n",
        "    corresponding label.\n",
        "    '''\n",
        "    groups         = []\n",
        "    label_folders  = os.listdir(input_folder)\n",
        "    index          = 0\n",
        "    for label_folder in sorted(label_folders):\n",
        "        label_folder_path = os.path.join(input_folder, label_folder)\n",
        "        if os.path.isdir(label_folder_path):\n",
        "            group_folders = os.listdir(label_folder_path)\n",
        "            for group_folder in group_folders:\n",
        "                if group_folder != 'Annotation':\n",
        "                    groups.append([os.path.join(label_folder_path, group_folder), index])\n",
        "            index += 1\n",
        "\n",
        "    return groups\n",
        "def split_data(groups, file_ext):\n",
        "    '''\n",
        "    Split the data at random for train, eval and test set.\n",
        "    '''\n",
        "    group_count = len(groups)\n",
        "    indices = np.arange(group_count)\n",
        "\n",
        "    np.random.seed(0) # Make it deterministic.\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    # 80% training and 20% test.\n",
        "    train_count = int(0.8 * group_count)\n",
        "    test_count  = group_count - train_count\n",
        "\n",
        "    train = []\n",
        "    test  = []\n",
        "\n",
        "    for i in range(train_count):\n",
        "        group = groups[indices[i]]\n",
        "        video_files = os.listdir(group[0])\n",
        "        for video_file in video_files:\n",
        "            video_file_path = os.path.join(group[0], video_file)\n",
        "            if os.path.isfile(video_file_path):\n",
        "                video_file_path = os.path.abspath(video_file_path)\n",
        "                ext = os.path.splitext(video_file_path)[1]\n",
        "                if (ext == file_ext):\n",
        "                    # make sure we have enough frames and the file isn't corrupt\n",
        "                    video_reader = imageio.get_reader(video_file_path, 'ffmpeg')\n",
        "                    if len(video_reader) >= 16:\n",
        "                        train.append([video_file_path, group[1]])\n",
        "\n",
        "    for i in range(train_count, train_count + test_count):\n",
        "        group = groups[indices[i]]\n",
        "        video_files = os.listdir(group[0])\n",
        "        for video_file in video_files:\n",
        "            video_file_path = os.path.join(group[0], video_file)\n",
        "            if os.path.isfile(video_file_path):\n",
        "                video_file_path = os.path.abspath(video_file_path)\n",
        "                ext = os.path.splitext(video_file_path)[1]\n",
        "                if (ext == file_ext):\n",
        "                    # make sure we have enough frames and the file isn't corrupt\n",
        "                    video_reader = imageio.get_reader(video_file_path, 'ffmpeg')\n",
        "                    if len(video_reader) >= 16:\n",
        "                        test.append([video_file_path, group[1]])\n",
        "\n",
        "    return train, test\n",
        "\n",
        "def write_to_csv(items, file_path):\n",
        "    '''\n",
        "    Write file path and its target pair in a CSV file format.\n",
        "    '''\n",
        "    if sys.version_info[0] < 3:\n",
        "        with open(file_path, 'wb') as csv_file:\n",
        "            writer = csv.writer(csv_file, delimiter=',')\n",
        "            for item in items:\n",
        "                writer.writerow(item)\n",
        "    else:\n",
        "        with open(file_path, 'w', newline='') as csv_file:\n",
        "            writer = csv.writer(csv_file, delimiter=',')\n",
        "            for item in items:\n",
        "                writer.writerow(item)\n",
        "\n",
        "def generate_and_save_labels():\n",
        "    groups = load_groups('./action_youtube_naudio')\n",
        "    train, test = split_data(groups, '.avi')\n",
        "\n",
        "    write_to_csv(train, os.path.join('.', 'train_map.csv'))\n",
        "    write_to_csv(test, os.path.join('.', 'test_map.csv'))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    os.chdir(os.path.abspath(os.path.dirname(\"__file__\")))\n",
        "    download_and_extract('https://www.crcv.ucf.edu/data/YouTube_DataSet_Annotated.zip')\n",
        "    print ('Writing train and test CSV file...')\n",
        "    generate_and_save_labels()\n",
        "    print ('Done.')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.crcv.ucf.edu/data/YouTube_DataSet_Annotated.zip\n",
            "Done downloading, start extracting.\n",
            "Done extracting.\n",
            "Writing train and test CSV file...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXVOyp83si3o",
        "outputId": "14ddbb5a-7240-447e-8db0-5edc00a95ce8"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import csv\n",
        "import sys\n",
        "import numpy as np\n",
        "import imageio\n",
        "\n",
        "import ssl\n",
        "\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "try:\n",
        "    from urllib.request import urlretrieve\n",
        "except ImportError:\n",
        "    from urllib import urlretrieve\n",
        "\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "def download_and_extract(src):\n",
        "    print ('Downloading ' + src)\n",
        "    zip_file, h = urlretrieve(src, './delete.me')\n",
        "    print ('Done downloading, start extracting.')\n",
        "    try:\n",
        "        with ZipFile(zip_file, 'r') as zfile:\n",
        "            zfile.extractall('.')\n",
        "            print ('Done extracting.')\n",
        "    finally:\n",
        "        os.remove(zip_file)\n",
        "\n",
        "def load_groups(input_folder):\n",
        "    '''\n",
        "    Load the list of sub-folders into a python list with their\n",
        "    corresponding label.\n",
        "    '''\n",
        "    groups         = []\n",
        "    label_folders  = os.listdir(input_folder)\n",
        "    index          = 0\n",
        "    for label_folder in sorted(label_folders):\n",
        "        label_folder_path = os.path.join(input_folder, label_folder)\n",
        "        if os.path.isdir(label_folder_path):\n",
        "            group_folders = os.listdir(label_folder_path)\n",
        "            for group_folder in group_folders:\n",
        "                if group_folder != 'Annotation':\n",
        "                    groups.append([os.path.join(label_folder_path, group_folder), index])\n",
        "            index += 1\n",
        "\n",
        "    return groups\n",
        "def split_data(groups, file_ext):\n",
        "    '''\n",
        "    Split the data at random for train, eval and test set.\n",
        "    '''\n",
        "    group_count = len(groups)\n",
        "    indices = np.arange(group_count)\n",
        "\n",
        "    np.random.seed(0) # Make it deterministic.\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    # 80% training and 20% test.\n",
        "    train_count = int(0.8 * group_count)\n",
        "    test_count  = group_count - train_count\n",
        "\n",
        "    train = []\n",
        "    test  = []\n",
        "\n",
        "    for i in range(train_count):\n",
        "        group = groups[indices[i]]\n",
        "        video_files = os.listdir(group[0])\n",
        "        for video_file in video_files:\n",
        "            video_file_path = os.path.join(group[0], video_file)\n",
        "            if os.path.isfile(video_file_path):\n",
        "                video_file_path = os.path.abspath(video_file_path)\n",
        "                ext = os.path.splitext(video_file_path)[1]\n",
        "                if (ext == file_ext):\n",
        "                    # make sure we have enough frames and the file isn't corrupt\n",
        "                    video_reader = imageio.get_reader(video_file_path, 'ffmpeg')\n",
        "                    if len(video_reader) >= 16:\n",
        "                        train.append([video_file_path, group[1]])\n",
        "\n",
        "    for i in range(train_count, train_count + test_count):\n",
        "        group = groups[indices[i]]\n",
        "        video_files = os.listdir(group[0])\n",
        "        for video_file in video_files:\n",
        "            video_file_path = os.path.join(group[0], video_file)\n",
        "            if os.path.isfile(video_file_path):\n",
        "                video_file_path = os.path.abspath(video_file_path)\n",
        "                ext = os.path.splitext(video_file_path)[1]\n",
        "                if (ext == file_ext):\n",
        "                    # make sure we have enough frames and the file isn't corrupt\n",
        "                    video_reader = imageio.get_reader(video_file_path, 'ffmpeg')\n",
        "                    if len(video_reader) >= 16:\n",
        "                        test.append([video_file_path, group[1]])\n",
        "\n",
        "    return train, test\n",
        "\n",
        "def write_to_csv(items, file_path):\n",
        "    '''\n",
        "    Write file path and its target pair in a CSV file format.\n",
        "    '''\n",
        "    if sys.version_info[0] < 3:\n",
        "        with open(file_path, 'wb') as csv_file:\n",
        "            writer = csv.writer(csv_file, delimiter=',')\n",
        "            for item in items:\n",
        "                writer.writerow(item)\n",
        "    else:\n",
        "        with open(file_path, 'w', newline='') as csv_file:\n",
        "            writer = csv.writer(csv_file, delimiter=',')\n",
        "            for item in items:\n",
        "                writer.writerow(item)\n",
        "\n",
        "def generate_and_save_labels():\n",
        "    groups = load_groups('./action_youtube_naudio')\n",
        "    train, test = split_data(groups, '.avi')\n",
        "\n",
        "    write_to_csv(train, os.path.join('.', 'train_map.csv'))\n",
        "    write_to_csv(test, os.path.join('.', 'test_map.csv'))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    os.chdir(os.path.abspath(os.path.dirname(\"__file__\")))\n",
        "    download_and_extract('https://www.crcv.ucf.edu/data/YouTube_DataSet_Annotated.zip')\n",
        "    print ('Writing train and test CSV file...')\n",
        "    generate_and_save_labels()\n",
        "    print ('Done.')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.crcv.ucf.edu/data/YouTube_DataSet_Annotated.zip\n",
            "Done downloading, start extracting.\n",
            "Done extracting.\n",
            "Writing train and test CSV file...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmSymFDmqDRn",
        "outputId": "1735ff92-4611-4184-b6bc-d7447ab3bc14"
      },
      "source": [
        "!apt-get install --no-install-recommends openmpi-bin libopenmpi-dev libopencv-dev python3-opencv python-opencv && ln -sf /usr/lib/x86_64-linux-gnu/libmpi_cxx.so /usr/lib/x86_64-linux-gnu/libmpi_cxx.so.1 && ln -sf /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so.12 && ln -sf /usr/lib/x86_64-linux-gnu/libmpi.so /usr/lib/x86_64-linux-gnu/libmpi.so.12 && pip install cntk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libopenmpi-dev is already the newest version (2.1.1-8).\n",
            "openmpi-bin is already the newest version (2.1.1-8).\n",
            "openmpi-bin set to manually installed.\n",
            "libopencv-dev is already the newest version (3.2.0+dfsg-4ubuntu0.1).\n",
            "The following NEW packages will be installed:\n",
            "  python-opencv python3-opencv\n",
            "0 upgraded, 2 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 1,069 kB of archives.\n",
            "After this operation, 5,885 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-opencv amd64 3.2.0+dfsg-4ubuntu0.1 [535 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-opencv amd64 3.2.0+dfsg-4ubuntu0.1 [534 kB]\n",
            "Fetched 1,069 kB in 1s (1,069 kB/s)\n",
            "Selecting previously unselected package python-opencv.\n",
            "(Reading database ... 144793 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opencv_3.2.0+dfsg-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-opencv (3.2.0+dfsg-4ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-opencv.\n",
            "Preparing to unpack .../python3-opencv_3.2.0+dfsg-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking python3-opencv (3.2.0+dfsg-4ubuntu0.1) ...\n",
            "Setting up python3-opencv (3.2.0+dfsg-4ubuntu0.1) ...\n",
            "Setting up python-opencv (3.2.0+dfsg-4ubuntu0.1) ...\n",
            "Collecting cntk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/02/0fbfa3ec554414150be46fde7a8e687104db944a6a55dfdbffe421373695/cntk-2.7.post1-cp36-cp36m-manylinux1_x86_64.whl (75.1MB)\n",
            "\u001b[K     |████████████████████████████████| 75.1MB 53kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from cntk) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from cntk) (1.4.1)\n",
            "Installing collected packages: cntk\n",
            "Successfully installed cntk-2.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC6XqZ4jtfOH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNkAbNpPqTxw"
      },
      "source": [
        "from __future__ import print_function\n",
        "import sys\n",
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "from random import randint\n",
        "\n",
        "from PIL import Image\n",
        "import imageio\n",
        "\n",
        "import cntk as C\n",
        "from cntk.logging import *\n",
        "from cntk.debugging import set_computation_network_trace_level\n",
        "\n",
        "# Paths relative to current python file.\n",
        "abs_path   = os.path.dirname(os.path.abspath(__file__))\n",
        "data_path  = os.path.join(abs_path, \"..\", \"..\", \"DataSets\", \"UCF11\")\n",
        "model_path = os.path.join(abs_path, \"Models\")\n",
        "\n",
        "# Define the reader for both training and evaluation action.\n",
        "class VideoReader(object):\n",
        "    '''\n",
        "    A simple VideoReader: \n",
        "    It iterates through each video and select 16 frames as\n",
        "    stacked numpy arrays.\n",
        "    Similar to http://vlg.cs.dartmouth.edu/c3d/c3d_video.pdf\n",
        "    '''\n",
        "    def __init__(self, map_file, label_count, is_training, limit_epoch_size=sys.maxsize):\n",
        "        '''\n",
        "        Load video file paths and their corresponding labels.\n",
        "        '''\n",
        "        self.map_file        = map_file\n",
        "        self.label_count     = label_count\n",
        "        self.width           = 112\n",
        "        self.height          = 112\n",
        "        self.sequence_length = 16\n",
        "        self.channel_count   = 3\n",
        "        self.is_training     = is_training\n",
        "        self.video_files     = []\n",
        "        self.targets         = []\n",
        "        self.batch_start     = 0\n",
        "\n",
        "        map_file_dir = os.path.dirname(map_file)\n",
        "\n",
        "        with open(map_file) as csv_file:\n",
        "            data = csv.reader(csv_file)\n",
        "            for row in data:\n",
        "                self.video_files.append(os.path.join(map_file_dir, row[0]))\n",
        "                target = [0.0] * self.label_count\n",
        "                target[int(row[1])] = 1.0\n",
        "                self.targets.append(target)\n",
        "\n",
        "        self.indices = np.arange(len(self.video_files))\n",
        "        if self.is_training:\n",
        "            np.random.shuffle(self.indices)\n",
        "        self.epoch_size = min(len(self.video_files), limit_epoch_size)\n",
        "\n",
        "    def size(self):\n",
        "        return self.epoch_size\n",
        "            \n",
        "    def has_more(self):\n",
        "        if self.batch_start < self.size():\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def reset(self):\n",
        "        if self.is_training:\n",
        "            np.random.shuffle(self.indices)\n",
        "        self.batch_start = 0\n",
        "\n",
        "    def next_minibatch(self, batch_size):\n",
        "        '''\n",
        "        Return a mini batch of sequence frames and their corresponding ground truth.\n",
        "        '''\n",
        "        batch_end = min(self.batch_start + batch_size, self.size())\n",
        "        current_batch_size = batch_end - self.batch_start\n",
        "        if current_batch_size < 0:\n",
        "            raise Exception('Reach the end of the training data.')\n",
        "\n",
        "        inputs  = np.empty(shape=(current_batch_size, self.channel_count, self.sequence_length, self.height, self.width), dtype=np.float32)\n",
        "        targets = np.empty(shape=(current_batch_size, self.label_count), dtype=np.float32)\n",
        "        for idx in range(self.batch_start, batch_end):\n",
        "            index = self.indices[idx]\n",
        "            inputs[idx - self.batch_start, :, :, :, :] = self._select_features(self.video_files[index])\n",
        "            targets[idx - self.batch_start, :]         = self.targets[index]\n",
        "\n",
        "        self.batch_start += current_batch_size\n",
        "        return inputs, targets, current_batch_size\n",
        "\n",
        "    def _select_features(self, video_file):\n",
        "        '''\n",
        "        Select a sequence of frames from video_file and return them as\n",
        "        a Tensor.\n",
        "        '''\n",
        "        video_reader = imageio.get_reader(video_file, 'ffmpeg')\n",
        "        num_frames   = len(video_reader)\n",
        "        if self.sequence_length > num_frames:\n",
        "            raise ValueError('Sequence length {} is larger then the total number of frames {} in {}.'.format(self.sequence_length, num_frames, video_file))\n",
        "\n",
        "        # select which sequence frames to use.\n",
        "        step = 1\n",
        "        expanded_sequence = self.sequence_length\n",
        "        if num_frames > 2*self.sequence_length:\n",
        "            step = 2\n",
        "            expanded_sequence = 2*self.sequence_length\n",
        "\n",
        "        seq_start = int(num_frames/2) - int(expanded_sequence/2)\n",
        "        if self.is_training:\n",
        "            seq_start = randint(0, num_frames - expanded_sequence)\n",
        "\n",
        "        frame_range = [seq_start + step*i for i in range(self.sequence_length)]            \n",
        "        video_frames = []\n",
        "        for frame_index in frame_range:\n",
        "            video_frames.append(self._read_frame(video_reader.get_data(frame_index)))\n",
        "        \n",
        "        return np.stack(video_frames, axis=1)\n",
        "\n",
        "    def _read_frame(self, data):\n",
        "        '''\n",
        "        Based on http://vlg.cs.dartmouth.edu/c3d/c3d_video.pdf\n",
        "        We resize the image to 128x171 first, then selecting a 112x112\n",
        "        crop.\n",
        "        '''\n",
        "        if (self.width >= 171) or (self.height >= 128):\n",
        "            raise ValueError(\"Target width need to be less than 171 and target height need to be less than 128.\")\n",
        "        \n",
        "        image = Image.fromarray(data)\n",
        "        image.thumbnail((171, 128), Image.ANTIALIAS)\n",
        "        \n",
        "        center_w = image.size[0] / 2\n",
        "        center_h = image.size[1] / 2\n",
        "\n",
        "        image = image.crop((center_w - self.width  / 2,\n",
        "                            center_h - self.height / 2,\n",
        "                            center_w + self.width  / 2,\n",
        "                            center_h + self.height / 2))\n",
        "        \n",
        "        norm_image = np.array(image, dtype=np.float32)\n",
        "        norm_image -= 127.5\n",
        "        norm_image /= 127.5\n",
        "\n",
        "        # (channel, height, width)\n",
        "        return np.ascontiguousarray(np.transpose(norm_image, (2, 0, 1)))\n",
        "\n",
        "# Creates and trains a feedforward classification model for UCF11 action videos\n",
        "def conv3d_ucf11(train_reader, test_reader, max_epochs=30):\n",
        "    # Replace 0 with 1 to get detailed log.\n",
        "    set_computation_network_trace_level(0)\n",
        "\n",
        "    # These values must match for both train and test reader.\n",
        "    image_height       = train_reader.height\n",
        "    image_width        = train_reader.width\n",
        "    num_channels       = train_reader.channel_count\n",
        "    sequence_length    = train_reader.sequence_length\n",
        "    num_output_classes = train_reader.label_count\n",
        "\n",
        "    # Input variables denoting the features and label data\n",
        "    input_var = C.input_variable((num_channels, sequence_length, image_height, image_width), np.float32)\n",
        "    label_var = C.input_variable(num_output_classes, np.float32)\n",
        "\n",
        "    # Instantiate simple 3D Convolution network inspired by VGG network \n",
        "    # and http://vlg.cs.dartmouth.edu/c3d/c3d_video.pdf\n",
        "    with C.default_options (activation=C.relu):\n",
        "        z = C.layers.Sequential([\n",
        "            C.layers.Convolution3D((3,3,3), 64, pad=True),\n",
        "            C.layers.MaxPooling((1,2,2), (1,2,2)),\n",
        "            C.layers.For(range(3), lambda i: [\n",
        "                C.layers.Convolution3D((3,3,3), [96, 128, 128][i], pad=True),\n",
        "                C.layers.Convolution3D((3,3,3), [96, 128, 128][i], pad=True),\n",
        "                C.layers.MaxPooling((2,2,2), (2,2,2))\n",
        "            ]),\n",
        "            C.layers.For(range(2), lambda : [\n",
        "                C.layers.Dense(1024), \n",
        "                C.layers.Dropout(0.5)\n",
        "            ]),\n",
        "            C.layers.Dense(num_output_classes, activation=None)\n",
        "        ])(input_var)\n",
        "    \n",
        "    # loss and classification error.\n",
        "    ce = C.cross_entropy_with_softmax(z, label_var)\n",
        "    pe = C.classification_error(z, label_var)\n",
        "\n",
        "    # training config\n",
        "    train_epoch_size     = train_reader.size()\n",
        "    train_minibatch_size = 2\n",
        "\n",
        "    # Set learning parameters\n",
        "    lr_per_sample          = [0.01]*10+[0.001]*10+[0.0001]\n",
        "    lr_schedule            = C.learning_rate_schedule(lr_per_sample, epoch_size=train_epoch_size, unit=C.UnitType.sample)\n",
        "    momentum_time_constant = 4096\n",
        "    mm_schedule            = C.momentum_as_time_constant_schedule([momentum_time_constant])\n",
        "\n",
        "    # Instantiate the trainer object to drive the model training\n",
        "    learner = C.momentum_sgd(z.parameters, lr_schedule, mm_schedule, True)\n",
        "    progress_printer = ProgressPrinter(tag='Training', num_epochs=max_epochs)\n",
        "    trainer = C.Trainer(z, (ce, pe), learner, progress_printer)\n",
        "\n",
        "    log_number_of_parameters(z) ; print()\n",
        "\n",
        "    # Get minibatches of images to train with and perform model training\n",
        "    for epoch in range(max_epochs):       # loop over epochs\n",
        "        train_reader.reset()\n",
        "\n",
        "        while train_reader.has_more():\n",
        "            videos, labels, current_minibatch = train_reader.next_minibatch(train_minibatch_size)\n",
        "            trainer.train_minibatch({input_var : videos, label_var : labels})\n",
        "\n",
        "        trainer.summarize_training_progress()\n",
        "\n",
        "    # Test data for trained model\n",
        "    epoch_size     = test_reader.size()\n",
        "    test_minibatch_size = 2\n",
        "\n",
        "    # process minibatches and evaluate the model\n",
        "    metric_numer    = 0\n",
        "    metric_denom    = 0\n",
        "    minibatch_index = 0\n",
        "\n",
        "    test_reader.reset()    \n",
        "    while test_reader.has_more():\n",
        "        videos, labels, current_minibatch = test_reader.next_minibatch(test_minibatch_size)\n",
        "        # minibatch data to be trained with\n",
        "        metric_numer += trainer.test_minibatch({input_var : videos, label_var : labels}) * current_minibatch\n",
        "        metric_denom += current_minibatch\n",
        "        # Keep track of the number of samples processed so far.\n",
        "        minibatch_index += 1\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Final Results: Minibatch[1-{}]: errs = {:0.2f}% * {}\".format(minibatch_index+1, (metric_numer*100.0)/metric_denom, metric_denom))\n",
        "    print(\"\")\n",
        "\n",
        "    return metric_numer/metric_denom\n",
        "\n",
        "if __name__=='__main__':\n",
        "    num_output_classes = 11\n",
        "    train_reader = VideoReader(os.path.join(data_path, '/content/train_map.csv'), num_output_classes, True)\n",
        "    test_reader  = VideoReader(os.path.join(data_path, '/content/test_map.csv'), num_output_classes, False)\n",
        "        \n",
        "    conv3d_ucf11(train_reader, test_reader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AqWP4JSpwdg",
        "outputId": "e17850c9-2cc5-40ca-9212-65a5a8017356"
      },
      "source": [
        "!python /content/Drowning-Risk-Analysis/VideoDataset/install_ufc11.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.crcv.ucf.edu/data/YouTube_DataSet_Annotated.zip\n",
            "Done downloading, start extracting.\n",
            "Done extracting.\n",
            "Writing train and test CSV file...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}